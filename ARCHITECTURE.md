# ğŸ—ï¸ Health Hackathon RAG System - Technical Architecture

## System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HEALTH HACKATHON SYSTEM                       â”‚
â”‚                 RAG-Powered Medical Information Bot              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PRESENTATION LAYER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Admin Dashboard             â”‚   Patient Chat Interface         â”‚
â”‚   (admin_health.html)         â”‚   (chat_health.html)            â”‚
â”‚                               â”‚                                  â”‚
â”‚   â€¢ Upload PDFs               â”‚   â€¢ Ask Questions               â”‚
â”‚   â€¢ View Documents            â”‚   â€¢ View Responses              â”‚
â”‚   â€¢ Delete Documents          â”‚   â€¢ See Sources                 â”‚
â”‚   â€¢ View Statistics           â”‚   â€¢ Check Confidence            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APPLICATION LAYER                            â”‚
â”‚                        (Flask - app.py)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  Routes:                        Middleware:                      â”‚
â”‚  â€¢ /admin/auth                  â€¢ Session Management             â”‚
â”‚  â€¢ /admin/upload                â€¢ Token Authentication           â”‚
â”‚  â€¢ /admin/documents             â€¢ File Validation                â”‚
â”‚  â€¢ /admin/delete/<file>         â€¢ Error Handling                 â”‚
â”‚  â€¢ /chat/query                  â€¢ Logging                        â”‚
â”‚  â€¢ /health                                                        â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       SERVICE LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OllamaService       â”‚  RetrievalService    â”‚ DocumentProcessor â”‚
â”‚  (ollama_service.py) â”‚ (retrieval_service.py)â”‚(document_processorâ”‚
â”‚                      â”‚                       â”‚      .py)        â”‚
â”‚  â€¢ LLM inference     â”‚  â€¢ Semantic search   â”‚  â€¢ PDF extractionâ”‚
â”‚  â€¢ RAG response      â”‚  â€¢ Embedding gen.    â”‚  â€¢ Text chunking â”‚
â”‚  â€¢ Prompt building   â”‚  â€¢ Similarity calc.  â”‚  â€¢ Validation    â”‚
â”‚  â€¢ Safety checks     â”‚  â€¢ Top-K retrieval   â”‚  â€¢ Page tracking â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                      â”‚
         â”‚                       â”‚                      â”‚
         â–¼                       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ollama API     â”‚    â”‚ Sentence         â”‚   â”‚ PDFPlumber     â”‚
â”‚  localhost:11434â”‚    â”‚ Transformers     â”‚   â”‚ Library        â”‚
â”‚                 â”‚    â”‚ (all-MiniLM-L6)  â”‚   â”‚                â”‚
â”‚  â€¢ llama3       â”‚    â”‚                  â”‚   â”‚ â€¢ Text extract â”‚
â”‚  â€¢ Local exec.  â”‚    â”‚ â€¢ Embeddings     â”‚   â”‚ â€¢ Page info    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA LAYER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  knowledge_base_     â”‚  uploads_health/     â”‚  upload_logs_     â”‚
â”‚  health.json         â”‚                      â”‚  health.json      â”‚
â”‚                      â”‚                      â”‚                   â”‚
â”‚  [                   â”‚  â€¢ PDF files         â”‚  [                â”‚
â”‚    {                 â”‚  â€¢ Secure storage    â”‚    {              â”‚
â”‚      "id": 1,        â”‚  â€¢ Original docs     â”‚      "filename",  â”‚
â”‚      "text": "...",  â”‚                      â”‚      "timestamp", â”‚
â”‚      "source": "...",â”‚                      â”‚      "chunks",    â”‚
â”‚      "page": 3       â”‚                      â”‚      "status"     â”‚
â”‚    },                â”‚                      â”‚    }              â”‚
â”‚    ...               â”‚                      â”‚  ]                â”‚
â”‚  ]                   â”‚                      â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## RAG Pipeline (Detailed)

### 1. Document Upload Flow

```
Admin uploads PDF
       â”‚
       â–¼
[Validation]
 â€¢ File size check (<50MB)
 â€¢ PDF format verification
 â€¢ Text extraction test
       â”‚
       â–¼
[Text Extraction]
 â€¢ PDFPlumber reads each page
 â€¢ Adds [Page N] markers
 â€¢ Concatenates to full text
       â”‚
       â–¼
[Chunking]
 â€¢ Split by page markers
 â€¢ Chunk into 300-word segments
 â€¢ Maintain page attribution
 â€¢ Keep chunks >= 40 words
       â”‚
       â–¼
[Embedding Generation]
 â€¢ Sentence Transformer encodes each chunk
 â€¢ Generates 384-dim vectors
 â€¢ Batch processing for efficiency
       â”‚
       â–¼
[Knowledge Base Update]
 â€¢ Assign unique IDs to chunks
 â€¢ Add to kb_docs array
 â€¢ Regenerate full embedding matrix
 â€¢ Save to knowledge_base_health.json
       â”‚
       â–¼
Success - Document indexed
```

### 2. Query Processing Flow

```
User asks question
       â”‚
       â–¼
[Question Embedding]
 â€¢ Encode question with Sentence Transformer
 â€¢ Generate 384-dim query vector
       â”‚
       â–¼
[Semantic Search]
 â€¢ Calculate cosine similarity: scores = kb_embeddings @ query_vector
 â€¢ Sort by similarity score
 â€¢ Filter by min_score (0.25)
 â€¢ Select top-K chunks (5)
       â”‚
       â”œâ”€[No relevant chunks]â”€â”€> Return "No information found"
       â”‚
       â–¼
[RAG Prompt Construction]
 â€¢ Build context from top-K chunks
 â€¢ Add source citations
 â€¢ Insert anti-hallucination instructions
 â€¢ Format: SYSTEM + CONTEXT + QUESTION
       â”‚
       â–¼
[Ollama Generation]
 â€¢ POST to localhost:11434/api/generate
 â€¢ Model: llama3
 â€¢ Temperature: 0.3 (factual)
 â€¢ Stream: false
 â€¢ Max tokens: 500
       â”‚
       â–¼
[Response Processing]
 â€¢ Extract generated text
 â€¢ Add medical disclaimer
 â€¢ Format source citations
 â€¢ Calculate confidence score
       â”‚
       â–¼
[Return to User]
 â€¢ Answer text
 â€¢ Sources list
 â€¢ Confidence score
 â€¢ Model name
```

---

## Component Details

### 1. OllamaService

**Responsibilities:**

- Connect to Ollama API
- Generate RAG responses
- Build safety-focused prompts
- Handle API errors

**Key Methods:**

```python
generate_rag_response(question, context_chunks, temperature, max_tokens)
â”œâ”€ Builds RAG prompt with anti-hallucination rules
â”œâ”€ Sends POST to Ollama API
â”œâ”€ Parses response
â”œâ”€ Calculates confidence
â””â”€ Returns formatted result

_build_rag_prompt(question, context_chunks)
â”œâ”€ Injects system instructions
â”œâ”€ Formats context with sources
â”œâ”€ Adds question
â””â”€ Returns complete prompt

test_connection()
â””â”€ Verifies Ollama is accessible and model is available
```

**Safety Features:**

- Explicit "use ONLY context" instructions
- Fallback for no-context scenarios
- Model-specific prompt optimization
- Error handling for timeouts

---

### 2. RetrievalService

**Responsibilities:**

- Semantic search via embeddings
- Generate embeddings for new documents
- Calculate relevance scores

**Key Methods:**

```python
retrieve_relevant_chunks(query, kb_docs, kb_embeddings, top_k, min_score)
â”œâ”€ Embed query
â”œâ”€ Compute similarity: np.dot(kb_embeddings, query_embedding)
â”œâ”€ Sort and filter by min_score
â”œâ”€ Return top-K chunks with scores
â””â”€ Add relevance labels (High/Medium/Low)

generate_embeddings(texts, batch_size)
â”œâ”€ Use Sentence Transformer
â”œâ”€ Batch processing for large sets
â”œâ”€ Normalize embeddings
â””â”€ Return numpy array
```

**Search Algorithm:**

```
Cosine Similarity = (kb_embedding Â· query_embedding) / (||kb|| Ã— ||query||)

Since embeddings are normalized during generation:
  ||kb|| = ||query|| = 1

Therefore:
  Cosine Similarity = kb_embedding Â· query_embedding (simple dot product)

Scores range from -1 to 1 (higher = more similar)
```

---

### 3. DocumentProcessor

**Responsibilities:**

- Extract text from PDFs
- Intelligent chunking with page info
- Validate PDFs

**Key Methods:**

```python
extract_text_from_pdf(pdf_path)
â”œâ”€ Open with PDFPlumber
â”œâ”€ Iterate through pages
â”œâ”€ Add [Page N] markers
â”œâ”€ Concatenate text
â””â”€ Return full text with markers

chunk_text_with_pages(text)
â”œâ”€ Split on [Page N] markers
â”œâ”€ For each page section:
â”‚   â”œâ”€ Split into words
â”‚   â”œâ”€ Create 300-word chunks
â”‚   â”œâ”€ Assign page number
â”‚   â””â”€ Clean text
â””â”€ Return list of (chunk_text, page_number)

process_pdf_to_chunks(pdf_path, source_name)
â”œâ”€ extract_text_from_pdf()
â”œâ”€ chunk_text_with_pages()
â”œâ”€ Build chunk dictionaries with metadata
â””â”€ Return list of chunk dicts
```

**Chunking Strategy:**

- **Size:** 300 words per chunk (balance between context and precision)
- **Overlap:** None (simplifies implementation, still effective)
- **Min size:** 40 words (filter out fragments)
- **Page tracking:** Essential for source attribution

---

## Data Models

### Chunk Object

```json
{
  "id": 42,
  "text": "Diabetes is a chronic disease that affects how your body turns food into energy. Most of the food you eat is broken down into sugar (glucose) and released into your bloodstream...",
  "source": "diabetes_overview.pdf",
  "page": 3
}
```

### Query Response

```json
{
  "success": true,
  "answer": "Diabetes symptoms include increased thirst, frequent urination, extreme hunger, unexplained weight loss, fatigue, blurred vision, and slow-healing sores.",
  "sources": [
    "diabetes_overview.pdf (Page 3)",
    "diabetes_overview.pdf (Page 4)"
  ],
  "confidence": 0.87,
  "model": "llama3"
}
```

### Upload Log Entry

```json
{
  "filename": "diabetes_guide.pdf",
  "timestamp": 1707609600.0,
  "chunks": 47,
  "status": "success"
}
```

---

## Security Architecture

### Authentication

- **Admin Token:** Stored in config (changeable via env var)
- **Session-based:** Flask-Session with filesystem storage
- **No JWT/OAuth:** Simple token auth (suitable for hackathon/demo)

### Input Validation

- **File upload:** PDF only, size limits, format validation
- **Query input:** Sanitized, trimmed
- **Filenames:** secure_filename() prevents path traversal

### Safety Mechanisms

1. **Prompt Engineering:** Explicit anti-hallucination instructions
2. **Context Grounding:** Responses must cite sources
3. **Confidence Scoring:** Warn users of low-confidence answers
4. **Medical Disclaimers:** Automatic on all responses
5. **No Context Fallback:** Explicitly state when information is unavailable

---

## Performance Optimization

### Embedding Generation

- **Batch processing:** 100 chunks at a time
- **Memory management:** Delete intermediate results
- **Normalization:** Embeddings normalized once during generation

### Knowledge Base Loading

- **Lazy loading:** KB loaded only on startup and after uploads
- **In-memory storage:** Fast retrieval without DB overhead
- **Numpy operations:** Vectorized similarity calculations

### Response Generation

- **Temperature tuning:** 0.3 for factual responses (vs 0.7 for creativity)
- **Token limits:** 500 tokens to balance quality and speed
- **Streaming disabled:** Wait for complete response (simpler implementation)

---

## Error Handling

### Hierarchical Error Handling

```
User Action
    â”‚
    â”œâ”€[Validation Error] â†’ HTTP 400, user-friendly message
    â”‚
    â”œâ”€[Processing Error] â†’ HTTP 500, log details, generic message to user
    â”‚
    â”œâ”€[Ollama Timeout] â†’ HTTP 503, "Service temporarily unavailable"
    â”‚
    â””â”€[Success] â†’ HTTP 200, formatted response
```

### Logging Strategy

```
[INFO]  - Normal operations
[WARNING] - Degraded but functional (e.g., Ollama model not found)
[ERROR] - Failures that prevent operation
```

All logs include timestamps and context.

---

## Deployment Considerations

### Local Development

- Default port: 5003 (avoid conflicts with common ports)
- Debug mode: Enabled for development
- Auto-reload: Enabled in dev

### Production Recommendations

1. **Use Waitress:** Production WSGI server (included in requirements)
2. **Environment variables:** Move secrets to `.env`
3. **Reverse proxy:** Use nginx for SSL/TLS
4. **Rate limiting:** Add Flask-Limiter
5. **Monitoring:** Add health checks and metrics

### Scaling

- **Horizontal:** Multiple Flask instances with load balancer
- **Vertical:** Increase Ollama resources, use GPU
- **Data:** Move from JSON to PostgreSQL/MongoDB for large KBs

---

## Technology Choices - Justification

### Why Ollama?

- âœ… Fully local (no API costs, no data privacy concerns)
- âœ… Easy to use (simple REST API)
- âœ… Multiple model support
- âœ… Active community
- âŒ Requires local resources (but worth it)

### Why Sentence Transformers?

- âœ… State-of-the-art semantic search
- âœ… Fast inference
- âœ… Good balance of speed and accuracy
- âœ… No fine-tuning needed

### Why Flask?

- âœ… Lightweight and simple
- âœ… Perfect for hackathons
- âœ… Excellent ecosystem
- âœ… Easy to extend

### Why JSON for KB?

- âœ… Simple and hackathon-friendly
- âœ… Human-readable
- âœ… No DB setup required
- âŒ Not scalable past ~10k chunks (but sufficient for hackathon)

---

## Future Enhancements (Post-Hackathon)

1. **Vector Database:** Migrate to Pinecone/Weaviate for scalability
2. **Hybrid Search:** Combine semantic + keyword search
3. **User Accounts:** Multi-user support with history
4. **Feedback Loop:** Allow users to rate answers, retrain
5. **Multi-modal:** Support images in PDFs (OCR + vision models)
6. **Real-time Streaming:** Stream Ollama responses for better UX
7. **Advanced Chunking:** Sliding window, hierarchical chunks
8. **Prompt Optimization:** A/B test different prompt templates

---

**Technical Architecture Document**
**Version 1.0 - February 2026**
**Built for Health Hackathon**
